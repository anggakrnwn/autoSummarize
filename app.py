# -*- coding: utf-8 -*-
"""autosummarize.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18damgofLFLxLk71PA3bryyKoz8ZZO_aD
"""

import streamlit as st
from newspaper import Article
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
from langdetect import detect
import spacy
from googletrans import Translator
from urllib.parse import urlparse

# Load model, tokenizer, and spaCy NER
model = AutoModelForSeq2SeqLM.from_pretrained("facebook/bart-large-cnn")
tokenizer = AutoTokenizer.from_pretrained("facebook/bart-large-cnn")
nlp = spacy.load("en_core_web_sm")

# Initialize Google Translator
translator = Translator()

# Function to validate URL
def is_valid_url(url):
    parsed = urlparse(url)
    return bool(parsed.netloc) and bool(parsed.scheme)

# Function to fetch article from URL
def get_article_from_url(url):
    try:
        article = Article(url)
        article.download()
        article.parse()
        return article.text
    except Exception:
        return None

# Function to split text by paragraphs
def split_text_by_paragraph(text, max_length):
    paragraphs = text.split("\n")
    parts = []
    current_part = ""
    for para in paragraphs:
        if len(current_part) + len(para) <= max_length:
            current_part += para + "\n"
        else:
            parts.append(current_part.strip())
            current_part = para + "\n"
    if current_part:
        parts.append(current_part.strip())
    return parts

# Function to highlight entities
def highlight_entities(text):
    doc = nlp(text)
    highlighted_text = text
    for ent in reversed(doc.ents):
        if ent.label_ in ["PERSON", "ORG"]:
            highlighted_text = (
                highlighted_text[:ent.start_char] +
                f"<span style='color: red; font-weight: bold;'>{ent.text}</span>" +
                highlighted_text[ent.end_char:]
            )
        elif ent.label_ == "GPE":
            highlighted_text = (
                highlighted_text[:ent.start_char] +
                f"<span style='color: yellow; font-weight: bold;'>{ent.text}</span>" +
                highlighted_text[ent.end_char:]
            )
    return highlighted_text

# Function to translate text using Google Translate API
def translate_text(text, target_lang):
    try:
        translated = translator.translate(text, dest=target_lang)
        return translated.text
    except Exception as e:
        return f"Translation failed! Error: {e}"

# Function to summarize and translate
def summarize_and_translate(url, target_lang):
    if not is_valid_url(url):
        return "Invalid URL!", "Invalid URL!"

    article_text = get_article_from_url(url)
    if not article_text:
        return "Article content not found!", "Article content not found!"

    original_lang = detect(article_text)
    max_length = 1024
    article_parts = split_text_by_paragraph(article_text, max_length)

    full_summary = ""
    for part in article_parts:
        inputs = tokenizer.encode(f"summarize: {part}", return_tensors="pt", max_length=max_length, truncation=True)
        summary_ids = model.generate(inputs, max_length=300, num_beams=6, temperature=0.7, early_stopping=True)
        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
        full_summary += summary + " "

    if original_lang == target_lang:
        highlighted_summary = highlight_entities(full_summary.strip())
        return article_text, highlighted_summary

    translated_summary = translate_text(full_summary.strip(), target_lang)
    highlighted_translated_summary = highlight_entities(translated_summary)
    return article_text, highlighted_translated_summary

# Streamlit UI
st.title("Summarizer and Translator")
st.write("Enter a URL to summarize and translate the content.")

input_url = st.text_input("Enter the URL:")
target_lang = st.selectbox("Select target language:", ["en", "id", "fr", "de", "es", "ja", "zh", "ru"])

if st.button("Summarize and Translate"):
    if input_url:
        full_article, summary = summarize_and_translate(input_url, target_lang)
        st.subheader("Full Article:")
        st.write(full_article)
        st.subheader("Summary:")
        st.markdown(summary, unsafe_allow_html=True)
    else:
        st.error("Please enter a valid URL!")